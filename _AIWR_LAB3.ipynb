{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df2e90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f822b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stockerbot-export1.csv')\n",
    "df = df.head(20)\n",
    "stop_words= [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266c4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean1 = r'@[A-Za-z0-9]+'\n",
    "clean2 = r'https?://[A-Za-z0-9./]+'\n",
    "comb = r'|'.join((clean1,clean2))\n",
    "clean3 = r'[^a-zA-Z]'\n",
    "clean = r'|'.join((comb,clean3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e3a6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "cleaned_tweets = []\n",
    "\n",
    "for i in range(0, len(df['text'])) :\n",
    "    tweets = re.sub(clean,' ',df['text'][i])\n",
    "    tweets = tweets.lower()\n",
    "    tweets = tweets.split()\n",
    "    tweets = [ps.stem(word) for word in tweets if not word in stop_words]\n",
    "    tweets = ' '.join(tweets)\n",
    "    cleaned_tweets.append(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed2de6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweets'] = cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c41821a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words = []\n",
    "for words in cleaned_tweets:\n",
    "    distinct_words.extend(words.split(' '))\n",
    "distinct_words.count('video')\n",
    "len(distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcc3eaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(set(distinct_words))\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3a4fe45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0197E+18</td>\n",
       "      <td>VIDEO: “I was in my office. I was minding my o...</td>\n",
       "      <td>Wed Jul 18 21:33:26 +0000 2018</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>video offic mind busi david solomon tell gs in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.01971E+18</td>\n",
       "      <td>The price of lumber $LB_F is down 22% since hi...</td>\n",
       "      <td>Wed Jul 18 22:22:47 +0000 2018</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>price lumber lb f sinc hit ytd high maci m tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.01971E+18</td>\n",
       "      <td>Who says the American Dream is dead? https://t...</td>\n",
       "      <td>Wed Jul 18 22:32:01 +0000 2018</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>American</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>say american dream dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.01972E+18</td>\n",
       "      <td>Barry Silbert is extremely optimistic on bitco...</td>\n",
       "      <td>Wed Jul 18 22:52:52 +0000 2018</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>BTC</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>https://twitter.com/i/web/status/1019716662587...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>barri silbert extrem optimist bitcoin predict ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.01972E+18</td>\n",
       "      <td>How satellites avoid attacks and space junk wh...</td>\n",
       "      <td>Wed Jul 18 23:00:01 +0000 2018</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>http://on.forbes.com/6013DqDDU</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>satellit avoid attack space junk circl earth paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.01972E+18</td>\n",
       "      <td>.@RealMoney's David Butler's favorite FANG sto...</td>\n",
       "      <td>Wed Jul 18 23:04:00 +0000 2018</td>\n",
       "      <td>jimcramer</td>\n",
       "      <td>FB-GOOGL-GOOG</td>\n",
       "      <td>Facebook*Alphabet*Alphabet</td>\n",
       "      <td>http://bit.ly/2NrYxje</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>david butler favorit fang stock isn realmoneys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.01972E+18</td>\n",
       "      <td>Don’t miss my convo with one of my favorite th...</td>\n",
       "      <td>Wed Jul 18 23:06:58 +0000 2018</td>\n",
       "      <td>ianbremmer</td>\n",
       "      <td>HRS</td>\n",
       "      <td>Harris</td>\n",
       "      <td>https://twitter.com/samharrisorg/status/101971...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>miss convo one favorit thinker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.01972E+18</td>\n",
       "      <td>U.S. intelligence documents on Nelson Mandela ...</td>\n",
       "      <td>Wed Jul 18 23:08:45 +0000 2018</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>INTC-USB</td>\n",
       "      <td>Intel*U.S.</td>\n",
       "      <td>https://reut.rs/2O0ypNf</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>u intellig document nelson mandela made public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.01972E+18</td>\n",
       "      <td>Senate wants emergency alerts to go out throug...</td>\n",
       "      <td>Wed Jul 18 23:09:00 +0000 2018</td>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>https://tcrn.ch/2L8DsgT</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>senat want emerg alert go netflix spotifi etc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  \\\n",
       "0   1.0197E+18  VIDEO: “I was in my office. I was minding my o...   \n",
       "1  1.01971E+18  The price of lumber $LB_F is down 22% since hi...   \n",
       "2  1.01971E+18  Who says the American Dream is dead? https://t...   \n",
       "3  1.01972E+18  Barry Silbert is extremely optimistic on bitco...   \n",
       "4  1.01972E+18  How satellites avoid attacks and space junk wh...   \n",
       "5  1.01972E+18  .@RealMoney's David Butler's favorite FANG sto...   \n",
       "6  1.01972E+18  Don’t miss my convo with one of my favorite th...   \n",
       "7  1.01972E+18  U.S. intelligence documents on Nelson Mandela ...   \n",
       "8  1.01972E+18  Senate wants emergency alerts to go out throug...   \n",
       "\n",
       "                        timestamp        source        symbols  \\\n",
       "0  Wed Jul 18 21:33:26 +0000 2018  GoldmanSachs             GS   \n",
       "1  Wed Jul 18 22:22:47 +0000 2018    StockTwits              M   \n",
       "2  Wed Jul 18 22:32:01 +0000 2018     TheStreet            AIG   \n",
       "3  Wed Jul 18 22:52:52 +0000 2018   MarketWatch            BTC   \n",
       "4  Wed Jul 18 23:00:01 +0000 2018        Forbes           ORCL   \n",
       "5  Wed Jul 18 23:04:00 +0000 2018     jimcramer  FB-GOOGL-GOOG   \n",
       "6  Wed Jul 18 23:06:58 +0000 2018    ianbremmer            HRS   \n",
       "7  Wed Jul 18 23:08:45 +0000 2018       Reuters       INTC-USB   \n",
       "8  Wed Jul 18 23:09:00 +0000 2018    TechCrunch           NFLX   \n",
       "\n",
       "                company_names  \\\n",
       "0           The Goldman Sachs   \n",
       "1                      Macy's   \n",
       "2                    American   \n",
       "3                     Bitcoin   \n",
       "4                      Oracle   \n",
       "5  Facebook*Alphabet*Alphabet   \n",
       "6                      Harris   \n",
       "7                  Intel*U.S.   \n",
       "8                     Netflix   \n",
       "\n",
       "                                                 url verified  \\\n",
       "0  https://twitter.com/i/web/status/1019696670777...     TRUE   \n",
       "1  https://twitter.com/i/web/status/1019709091038...     TRUE   \n",
       "2                            https://buff.ly/2L3kmc4     TRUE   \n",
       "3  https://twitter.com/i/web/status/1019716662587...     TRUE   \n",
       "4                     http://on.forbes.com/6013DqDDU     TRUE   \n",
       "5                              http://bit.ly/2NrYxje     TRUE   \n",
       "6  https://twitter.com/samharrisorg/status/101971...     TRUE   \n",
       "7                            https://reut.rs/2O0ypNf     TRUE   \n",
       "8                            https://tcrn.ch/2L8DsgT     TRUE   \n",
       "\n",
       "                                      cleaned_tweets  \n",
       "0  video offic mind busi david solomon tell gs in...  \n",
       "1  price lumber lb f sinc hit ytd high maci m tur...  \n",
       "2                            say american dream dead  \n",
       "3  barri silbert extrem optimist bitcoin predict ...  \n",
       "4  satellit avoid attack space junk circl earth paid  \n",
       "5  david butler favorit fang stock isn realmoneys...  \n",
       "6                     miss convo one favorit thinker  \n",
       "7     u intellig document nelson mandela made public  \n",
       "8      senat want emerg alert go netflix spotifi etc  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d666d9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barri silbert extrem optimist bitcoin predict new crypto entrant go zero'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_tweets'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e66d5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahead': [1, [12]],\n",
       " 'sinc': [1, [1]],\n",
       " 'gs': [1, [0]],\n",
       " 'space': [1, [4]],\n",
       " 'tighten': [1, [15]],\n",
       " 'jerom': [1, [12]],\n",
       " 'mvp': [1, [18]],\n",
       " 'share': [1, [13]],\n",
       " 'presid': [1, [16]],\n",
       " 'deal': [1, [11]],\n",
       " 'cut': [1, [13]],\n",
       " 'possibl': [1, [9]],\n",
       " 'propos': [1, [10]],\n",
       " 'cagl': [1, [16]],\n",
       " 'forecast': [1, [13]],\n",
       " 'come': [1, [12]],\n",
       " 'entrant': [1, [3]],\n",
       " 'fight': [1, [10]],\n",
       " 'tariff': [1, [13]],\n",
       " 'purchas': [1, [10]],\n",
       " 'f': [1, [0, 1, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17]],\n",
       " 'mandela': [1, [7]],\n",
       " 'file': [1, [14]],\n",
       " 'billion': [1, [15]],\n",
       " 'kemp': [1, [16]],\n",
       " 'summit': [1, [17]],\n",
       " 'satellit': [1, [4]],\n",
       " 'boycott': [1, [14]],\n",
       " 'expedit': [1, [10]],\n",
       " 'earth': [1, [4]],\n",
       " 'trader': [1, [12]],\n",
       " 'shoot': [1, [14]],\n",
       " 'hous': [1, [17]],\n",
       " 'spotifi': [1, [8]],\n",
       " 'casey': [1, [16]],\n",
       " 'lumber': [1, [1]],\n",
       " 'still': [2, [1, 19]],\n",
       " 'dream': [1, [2]],\n",
       " 'time': [1, [10]],\n",
       " 'ytd': [1, [1]],\n",
       " 'custom': [1, [14]],\n",
       " 'offic': [1, [0]],\n",
       " 'northern': [1, [19]],\n",
       " 'manag': [1, [9]],\n",
       " 'happen': [1, [1]],\n",
       " 'struggl': [1, [17]],\n",
       " 'casino': [1, [14]],\n",
       " 'world': [1, [19]],\n",
       " 'document': [1, [7]],\n",
       " 'm': [2, [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19]],\n",
       " 'georgia': [1, [16]],\n",
       " 'fund': [1, [9]],\n",
       " 'convo': [1, [6]],\n",
       " 'adjust': [1, [13]],\n",
       " 'laker': [1, [18]],\n",
       " 'bitcoin': [2, [3, 9]],\n",
       " 'alcoa': [1, [13]],\n",
       " 'trillion': [1, [15]],\n",
       " 'governor': [1, [16]],\n",
       " 'tell': [1, [0, 4, 7]],\n",
       " 'american': [1, [2]],\n",
       " 'miss': [1, [6]],\n",
       " 'expect': [1, [12]],\n",
       " 'brian': [1, [16]],\n",
       " 'gap': [1, [15]],\n",
       " 'nelson': [1, [7]],\n",
       " 'busi': [1, [0]],\n",
       " 'paid': [1, [4]],\n",
       " 'maci': [1, [1]],\n",
       " 'amazon': [1, [15]],\n",
       " 'say': [2, [2, 9]],\n",
       " 'stock': [1, [5]],\n",
       " 'via': [2, [12, 15]],\n",
       " 'avoid': [1, [4]],\n",
       " 'fang': [1, [5]],\n",
       " 'mgm': [1, [14]],\n",
       " 'name': [1, [18]],\n",
       " 'hit': [2, [1, 15, 17, 19]],\n",
       " 'go': [2, [3, 8, 16]],\n",
       " 'wa': [1, [0, 8, 10]],\n",
       " 'contain': [1, [17]],\n",
       " 'favorit': [2, [5, 6]],\n",
       " 'lawsuit': [1, [14]],\n",
       " 'exist': [1, [19]],\n",
       " 'hedg': [1, [9]],\n",
       " 'turnaround': [1, [1]],\n",
       " 'amp': [1, [10]],\n",
       " 'high': [1, [1]],\n",
       " 'valuat': [1, [15]],\n",
       " 'subspeci': [1, [19]],\n",
       " 'intellig': [1, [7]],\n",
       " 'warner': [1, [10]],\n",
       " 'netflix': [1, [8]],\n",
       " 'larsi': [1, [9]],\n",
       " 'new': [1, [3]],\n",
       " 'u': [3, [0, 1, 4, 5, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]],\n",
       " 'isn': [1, [5]],\n",
       " 'attack': [1, [4]],\n",
       " 'slide': [1, [13]],\n",
       " 'circl': [1, [4]],\n",
       " 'price': [1, [1]],\n",
       " 'k': [1, [4, 5, 6, 9, 11, 16, 18, 19]],\n",
       " 'bond': [1, [12]],\n",
       " 'one': [2, [5, 6, 11]],\n",
       " 'facebook': [1, [5]],\n",
       " 'endors': [2, [11, 16]],\n",
       " 'trump': [2, [16, 17]],\n",
       " 'mind': [1, [0]],\n",
       " 'intern': [1, [0]],\n",
       " 'inflat': [1, [12]],\n",
       " 'emerg': [1, [8]],\n",
       " 'rhino': [1, [19]],\n",
       " 'roger': [1, [11]],\n",
       " 'junk': [1, [4]],\n",
       " 'powel': [1, [12]],\n",
       " 'video': [1, [0]],\n",
       " 'sport': [1, [18]],\n",
       " 'earn': [1, [0, 11]],\n",
       " 'victim': [1, [14]],\n",
       " 'public': [1, [7]],\n",
       " 'silbert': [1, [3]],\n",
       " 'senat': [1, [8]],\n",
       " 'athlet': [1, [11]],\n",
       " 'cite': [1, [13]],\n",
       " 'dollar': [1, [15]],\n",
       " 'race': [2, [15, 16]],\n",
       " 'feder': [1, [11]],\n",
       " 'urg': [1, [14]],\n",
       " 'dead': [1, [2]],\n",
       " 'solomon': [1, [0]],\n",
       " 'white': [2, [17, 19]],\n",
       " 'headlin': [1, [18]],\n",
       " 'want': [1, [8]],\n",
       " 'predict': [1, [3]],\n",
       " 'alert': [1, [8]],\n",
       " 'marc': [1, [9]],\n",
       " 'barri': [1, [3]],\n",
       " 'lb': [1, [1, 3]],\n",
       " 'mammal': [1, [19]],\n",
       " 'butler': [1, [5]],\n",
       " 'ebitda': [1, [13]],\n",
       " 'optimist': [1, [3]],\n",
       " 'david': [2, [0, 5]],\n",
       " 'alphabet': [1, [5]],\n",
       " 'resort': [1, [14]],\n",
       " 'appeal': [1, [10]],\n",
       " 'endang': [1, [19]],\n",
       " 'fallout': [1, [17]],\n",
       " 'make': [2, [11, 19]],\n",
       " 'extrem': [1, [3]],\n",
       " 'realmoneysod': [1, [5]],\n",
       " 'uniqlo': [1, [11]],\n",
       " 'putin': [1, [17]],\n",
       " 'zero': [1, [3]],\n",
       " 'mass': [1, [14]],\n",
       " 'made': [1, [7]],\n",
       " 'crypto': [1, [3]],\n",
       " 'hart': [1, [18]],\n",
       " 'summer': [1, [18]],\n",
       " 'guard': [1, [18]],\n",
       " 'leagu': [1, [18]],\n",
       " 'two': [1, [19]],\n",
       " 'thinker': [1, [6]],\n",
       " 'etc': [1, [8]],\n",
       " 'learn': [1, [0]]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posting_list = {}\n",
    "\n",
    "for word in tokens:\n",
    "    lst = []\n",
    "    posting_list[word] = [distinct_words.count(word)]\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if (word in df['cleaned_tweets'][i]):\n",
    "            lst.append(i)\n",
    "    posting_list[word].append(lst)\n",
    "posting_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33d5a11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 5, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def search(word):\n",
    "    lst=[]\n",
    "    if word not in posting_list:\n",
    "        print('no docs found')\n",
    "    else:\n",
    "        for i in posting_list[word][1]:\n",
    "            lst.append(i)\n",
    "    return lst\n",
    "\n",
    "def boolean_query_and(query1,query2):\n",
    "    docs_1 = search(query1)\n",
    "    docs_2 = search(query2)\n",
    "    result = [value for value in docs_1 if value in docs_2]\n",
    "    return result\n",
    "\n",
    "def boolean_query_or(query1,query2):\n",
    "    docs_1 = search(query1)\n",
    "    docs_2 = search(query2)\n",
    "    result = list(set(docs_1+docs_2))\n",
    "    return result\n",
    "    \n",
    "documents = boolean_query_or(\"u\",\"guard\")\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93f96ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahead': [1, {12: [3]}],\n",
       " 'sinc': [1, {1: [5]}],\n",
       " 'gs': [1, {0: [8]}],\n",
       " 'space': [1, {4: [4]}],\n",
       " 'tighten': [1, {15: [2]}],\n",
       " 'jerom': [1, {12: [4]}],\n",
       " 'mvp': [1, {18: [7]}],\n",
       " 'share': [1, {13: [8]}],\n",
       " 'presid': [1, {16: [1]}],\n",
       " 'deal': [1, {11: [4]}],\n",
       " 'cut': [1, {13: [2]}],\n",
       " 'possibl': [1, {9: [9]}],\n",
       " 'propos': [1, {10: [2]}],\n",
       " 'cagl': [1, {16: [7]}],\n",
       " 'forecast': [1, {13: [5]}],\n",
       " 'come': [1, {12: [6]}],\n",
       " 'entrant': [1, {3: [9]}],\n",
       " 'fight': [1, {10: [5]}],\n",
       " 'tariff': [1, {13: [7]}],\n",
       " 'purchas': [1, {10: [9]}],\n",
       " 'f': [1, {1: [4]}],\n",
       " 'mandela': [1, {7: [5]}],\n",
       " 'file': [1, {14: [7]}],\n",
       " 'billion': [1, {15: [9]}],\n",
       " 'kemp': [1, {16: [5]}],\n",
       " 'summit': [1, {17: [8]}],\n",
       " 'satellit': [1, {4: [1]}],\n",
       " 'boycott': [1, {14: [3]}],\n",
       " 'expedit': [1, {10: [3]}],\n",
       " 'earth': [1, {4: [7]}],\n",
       " 'trader': [1, {12: [2]}],\n",
       " 'shoot': [1, {14: [10]}],\n",
       " 'hous': [1, {17: [2]}],\n",
       " 'spotifi': [1, {8: [7]}],\n",
       " 'casey': [1, {16: [6]}],\n",
       " 'lumber': [1, {1: [2]}],\n",
       " 'still': [2, {1: [12]}, {19: [5]}],\n",
       " 'dream': [1, {2: [3]}],\n",
       " 'time': [1, {10: [7]}],\n",
       " 'ytd': [1, {1: [7]}],\n",
       " 'custom': [1, {14: [1]}],\n",
       " 'offic': [1, {0: [2]}],\n",
       " 'northern': [1, {19: [2]}],\n",
       " 'manag': [1, {9: [3]}],\n",
       " 'happen': [1, {1: [13]}],\n",
       " 'struggl': [1, {17: [3]}],\n",
       " 'casino': [1, {14: [6]}],\n",
       " 'world': [1, {19: [8]}],\n",
       " 'document': [1, {7: [3]}],\n",
       " 'm': [2, {1: [10]}, {11: [9]}],\n",
       " 'georgia': [1, {16: [8]}],\n",
       " 'fund': [1, {9: [2]}],\n",
       " 'convo': [1, {6: [2]}],\n",
       " 'adjust': [1, {13: [3]}],\n",
       " 'laker': [1, {18: [1]}],\n",
       " 'bitcoin': [2, {3: [5]}, {9: [7]}],\n",
       " 'alcoa': [1, {13: [1]}],\n",
       " 'trillion': [1, {15: [4]}],\n",
       " 'governor': [1, {16: [9]}],\n",
       " 'tell': [1, {0: [7]}],\n",
       " 'american': [1, {2: [2]}],\n",
       " 'miss': [1, {6: [1]}],\n",
       " 'expect': [1, {12: [8]}],\n",
       " 'brian': [1, {16: [4]}],\n",
       " 'gap': [1, {15: [1]}],\n",
       " 'nelson': [1, {7: [4]}],\n",
       " 'busi': [1, {0: [4]}],\n",
       " 'paid': [1, {4: [8]}],\n",
       " 'maci': [1, {1: [9]}],\n",
       " 'amazon': [1, {15: [7]}],\n",
       " 'say': [2, {2: [1]}, {9: [6]}],\n",
       " 'stock': [1, {5: [5]}],\n",
       " 'via': [2, {12: [9]}, {15: [10]}],\n",
       " 'avoid': [1, {4: [2]}],\n",
       " 'fang': [1, {5: [4]}],\n",
       " 'mgm': [1, {14: [4]}],\n",
       " 'name': [1, {18: [4]}],\n",
       " 'hit': [2, {1: [6]}, {15: [8]}],\n",
       " 'go': [2, {3: [10]}, {8: [5]}],\n",
       " 'wa': [1, {0: [11]}],\n",
       " 'contain': [1, {17: [4]}],\n",
       " 'favorit': [2, {5: [3]}, {6: [4]}],\n",
       " 'lawsuit': [1, {14: [8]}],\n",
       " 'exist': [1, {19: [6]}],\n",
       " 'hedg': [1, {9: [1]}],\n",
       " 'turnaround': [1, {1: [11]}],\n",
       " 'amp': [1, {10: [6]}],\n",
       " 'high': [1, {1: [8]}],\n",
       " 'valuat': [1, {15: [6]}],\n",
       " 'subspeci': [1, {19: [10]}],\n",
       " 'intellig': [1, {7: [2]}],\n",
       " 'warner': [1, {10: [8]}],\n",
       " 'netflix': [1, {8: [6]}],\n",
       " 'larsi': [1, {9: [5]}],\n",
       " 'new': [1, {3: [7]}],\n",
       " 'u': [3, {7: [1]}, {10: [1]}, {18: [8]}],\n",
       " 'isn': [1, {5: [6]}],\n",
       " 'attack': [1, {4: [3]}],\n",
       " 'slide': [1, {13: [9]}],\n",
       " 'circl': [1, {4: [6]}],\n",
       " 'price': [1, {1: [1]}],\n",
       " 'k': [1, {9: [8]}],\n",
       " 'bond': [1, {12: [1]}],\n",
       " 'one': [2, {6: [3]}, {11: [6]}],\n",
       " 'facebook': [1, {5: [9]}],\n",
       " 'endors': [2, {11: [10]}, {16: [3]}],\n",
       " 'trump': [2, {16: [2]}, {17: [6]}],\n",
       " 'mind': [1, {0: [3]}],\n",
       " 'intern': [1, {0: [9]}],\n",
       " 'inflat': [1, {12: [7]}],\n",
       " 'emerg': [1, {8: [3]}],\n",
       " 'rhino': [1, {19: [4]}],\n",
       " 'roger': [1, {11: [1]}],\n",
       " 'junk': [1, {4: [5]}],\n",
       " 'powel': [1, {12: [5]}],\n",
       " 'video': [1, {0: [1]}],\n",
       " 'sport': [1, {18: [9]}],\n",
       " 'earn': [1, {11: [8]}],\n",
       " 'victim': [1, {14: [11]}],\n",
       " 'public': [1, {7: [7]}],\n",
       " 'silbert': [1, {3: [2]}],\n",
       " 'senat': [1, {8: [1]}],\n",
       " 'athlet': [1, {11: [7]}],\n",
       " 'cite': [1, {13: [6]}],\n",
       " 'dollar': [1, {15: [5]}],\n",
       " 'race': [2, {15: [3]}, {16: [10]}],\n",
       " 'feder': [1, {11: [2]}],\n",
       " 'urg': [1, {14: [2]}],\n",
       " 'dead': [1, {2: [4]}],\n",
       " 'solomon': [1, {0: [6]}],\n",
       " 'white': [2, {17: [1]}, {19: [3]}],\n",
       " 'headlin': [1, {18: [10]}],\n",
       " 'want': [1, {8: [2]}],\n",
       " 'predict': [1, {3: [6]}],\n",
       " 'alert': [1, {8: [4]}],\n",
       " 'marc': [1, {9: [4]}],\n",
       " 'barri': [1, {3: [1]}],\n",
       " 'lb': [1, {1: [3]}],\n",
       " 'mammal': [1, {19: [11]}],\n",
       " 'butler': [1, {5: [2]}],\n",
       " 'ebitda': [1, {13: [4]}],\n",
       " 'optimist': [1, {3: [4]}],\n",
       " 'david': [2, {0: [5]}, {5: [1]}],\n",
       " 'alphabet': [1, {5: [8]}],\n",
       " 'resort': [1, {14: [5]}],\n",
       " 'appeal': [1, {10: [4]}],\n",
       " 'endang': [1, {19: [9]}],\n",
       " 'fallout': [1, {17: [5]}],\n",
       " 'make': [2, {11: [5]}, {19: [7]}],\n",
       " 'extrem': [1, {3: [3]}],\n",
       " 'realmoneysod': [1, {5: [7]}],\n",
       " 'uniqlo': [1, {11: [3]}],\n",
       " 'putin': [1, {17: [7]}],\n",
       " 'zero': [1, {3: [11]}],\n",
       " 'mass': [1, {14: [9]}],\n",
       " 'made': [1, {7: [6]}],\n",
       " 'crypto': [1, {3: [8]}],\n",
       " 'hart': [1, {18: [3]}],\n",
       " 'summer': [1, {18: [5]}],\n",
       " 'guard': [1, {18: [2]}],\n",
       " 'leagu': [1, {18: [6]}],\n",
       " 'two': [1, {19: [1]}],\n",
       " 'thinker': [1, {6: [5]}],\n",
       " 'etc': [1, {8: [8]}],\n",
       " 'learn': [1, {0: [10]}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_posting_list = {}\n",
    "\n",
    "\n",
    "for word in tokens:\n",
    "    lst = []\n",
    "    positional_posting_list[word] = [distinct_words.count(word)]\n",
    "    for i in range(0,df.shape[0]):\n",
    "        dic = {} \n",
    "        dic[i] = []\n",
    "        if (word in df['cleaned_tweets'][i].split()):\n",
    "            list_words = df['cleaned_tweets'][i].split()\n",
    "            dic[i].extend([word_pos+1 for word_pos in range(len(list_words)) if list_words[word_pos]==word ])\n",
    "            lst.append(dic)\n",
    "    positional_posting_list[word].extend(lst)\n",
    "        \n",
    "positional_posting_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e81d411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def phrase_query(query):\n",
    "    items = query.split()\n",
    "    lst=[]\n",
    "    for j in range(len(items)-1):\n",
    "        word1 = positional_posting_list[items[j]][1:]\n",
    "        word2 = positional_posting_list[items[j+1]][1:]\n",
    "        for i in range(min(len(word1),len(word2))):\n",
    "            if (word1[i].keys()==word2[i].keys()):\n",
    "                docid = list(word1[i].keys())[0] \n",
    "                k=0\n",
    "                z=0\n",
    "                while (k<len(word1) and z<len(word2)):\n",
    "                    if (word1[i][docid][k]==word2[i][docid][z]-1):\n",
    "                        lst.append(docid)\n",
    "                        k=k+1\n",
    "                        z=z+1\n",
    "                    else:\n",
    "                        if (word1[i][docid][k]<word2[i][docid][z]):\n",
    "                            k=k+1\n",
    "                        else:\n",
    "                            z=z+1\n",
    "    for doc in lst:\n",
    "        if (lst.count(doc)!=len(items)-1):\n",
    "            lst.remove(doc)\n",
    "    lst = list(set(lst))\n",
    "    return lst\n",
    "\n",
    "res = phrase_query(\"barri silbert extrem optimist bitcoin predict new crypto entrant go zero\")\n",
    "res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06406d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15e56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c22ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
